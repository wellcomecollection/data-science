{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from scipy.spatial.distance import jaccard\n",
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector_dir = \"/Users/pimh/Desktop/feature_vectors/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector_ids = np.random.choice(os.listdir(feature_vector_dir), 25_000)\n",
    "# feature_vector_ids = os.listdir(feature_vector_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector_paths = [\n",
    "    os.path.join(feature_vector_dir, id) for id in feature_vector_ids\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors = []\n",
    "for path in feature_vector_paths:\n",
    "    with open(path) as f:\n",
    "        feature_vector = np.fromfile(f, dtype=np.float32)\n",
    "        feature_vectors.append(feature_vector)\n",
    "\n",
    "feature_vectors = np.stack(feature_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load column labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/column_labels.npy\", \"rb\") as f:\n",
    "    column_labels = np.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split feature vectors by label, and find clusters within groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = []\n",
    "\n",
    "for i in tqdm(np.unique(column_labels)):\n",
    "    feature_group = feature_vectors[:, column_labels == 1]\n",
    "    kmeans = KMeans(n_clusters=32).fit(feature_group)\n",
    "    clusters.append(kmeans.labels_)\n",
    "\n",
    "    with open(f\"models/kmeans_{i}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(kmeans, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode _all_ features using clustering models trained on subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector_ids = os.listdir(feature_vector_dir)\n",
    "\n",
    "feature_vector_paths = [\n",
    "    os.path.join(feature_vector_dir, id) for id in feature_vector_ids\n",
    "]\n",
    "\n",
    "feature_vectors = []\n",
    "for path in feature_vector_paths:\n",
    "    with open(path) as f:\n",
    "        feature_vector = np.fromfile(f, dtype=np.float32)\n",
    "        feature_vectors.append(feature_vector)\n",
    "\n",
    "feature_vectors = np.stack(feature_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = []\n",
    "\n",
    "for i in tqdm(np.unique(column_labels)):\n",
    "    with open(f\"models/kmeans_{i}.pkl\", \"rb\") as f:\n",
    "        kmeans = pickle.load(f)\n",
    "\n",
    "    feature_group = feature_vectors[:, column_labels == 1]\n",
    "    labels = kmeans.predict(feature_group)\n",
    "    clusters.append(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send data to elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = np.vstack(clusters).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listify_for_es(cluster_array):\n",
    "    return [f\"{i}-{val}\" for i, val in enumerate(cluster_array)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_es_client():\n",
    "    username = \"\"\n",
    "    password = \"\"\n",
    "    url = \"\"\n",
    "    return Elasticsearch(url, http_auth=(username, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"image-similarity-256-32\"\n",
    "\n",
    "es = get_es_client()\n",
    "es.indices.delete(index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es.indices.create(index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [\n",
    "    {\n",
    "        \"_index\": index_name,\n",
    "        \"_type\": \"feature_vector\",\n",
    "        \"_id\": feature_vector_id,\n",
    "        \"_source\": {\"feature_vector\": listify_for_es(cluster_array)},\n",
    "    }\n",
    "    for feature_vector_id, cluster_array in tqdm(zip(feature_vector_ids, clusters))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.bulk(es, actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(query_id):\n",
    "    base_url = (\n",
    "        \"https://iiif.wellcomecollection.org/image/{}.jpg/full/,300/0/default.jpg\"\n",
    "    )\n",
    "    response = requests.get(base_url.format(query_id))\n",
    "    image = Image.open(BytesIO(response.content))\n",
    "    return image\n",
    "\n",
    "\n",
    "def stack_images(images):\n",
    "    return Image.fromarray(\n",
    "        np.concatenate([np.array(image) for image in images], axis=1)\n",
    "    )\n",
    "\n",
    "\n",
    "def get_neighbour_images(query_id, index_name, n=10):\n",
    "    res = es.search(\n",
    "        index=index_name,\n",
    "        size=n,\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"more_like_this\": {\n",
    "                    \"fields\": [\"feature_vector.keyword\"],\n",
    "                    \"like\": [{\"_index\": index_name, \"_id\": query_id}],\n",
    "                    \"min_term_freq\": 1,\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "\n",
    "    neighbour_ids = [hit[\"_id\"] for hit in res[\"hits\"][\"hits\"]]\n",
    "    print(res[\"hits\"][\"total\"][\"value\"])\n",
    "    neighbour_images = [get_image(id) for id in neighbour_ids]\n",
    "    return stack_images(neighbour_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = np.random.choice(feature_vector_ids)\n",
    "print(query_id)\n",
    "\n",
    "get_image(query_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_neighbour_images(query_id, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
