{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists, join, dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_names(path, num, prefix):\n",
    "    names = {}\n",
    "    errors = 0  # debug\n",
    "    if num > 0:\n",
    "        with open(path, \"rt\", encoding=\"UTF-8\") as fin:\n",
    "            for line in fin:\n",
    "                try:\n",
    "                    name, number = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "                except ValueError:\n",
    "                    errors += 1\n",
    "                number = int(number)\n",
    "                if number >= num:\n",
    "                    break\n",
    "                else:\n",
    "                    if name.startswith(prefix):\n",
    "                        names[number] = name[7:]\n",
    "        print(errors)  # debug\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/mnt/efs/wikipedia/deeptype/wikidata/\"\n",
    "num_names_to_load = 43710495\n",
    "prefix = \"enwiki\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_names = load_names(\n",
    "    join(path, \"wikidata_wikititle2wikidata.tsv\"), num_names_to_load, prefix=prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load_wikidata_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarisaAsDict(object):\n",
    "    def __init__(self, marisa):\n",
    "        self.marisa = marisa\n",
    "\n",
    "    def get(self, key, fallback):\n",
    "        value = self.marisa.get(key, None)\n",
    "        if value is None:\n",
    "            return fallback\n",
    "        else:\n",
    "            return value[0][0]\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        value = self.marisa[key]\n",
    "        return value[0][0]\n",
    "\n",
    "    def __contains__(self, key):\n",
    "        return key in self.marisa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wikidata_ids(path, verbose=True):\n",
    "    wikidata_ids_inverted_path = join(path, \"wikidata_ids_inverted.marisa\")\n",
    "    with open(join(path, \"wikidata_ids.txt\"), \"rt\") as fin:\n",
    "        ids = fin.read().splitlines()\n",
    "    if exists(wikidata_ids_inverted_path):\n",
    "        print(\"exists\")\n",
    "        if verbose:\n",
    "            print(\"loading wikidata id -> index\")\n",
    "        name2index = MarisaAsDict(\n",
    "            marisa_trie.RecordTrie(\"i\").load(wikidata_ids_inverted_path)\n",
    "        )\n",
    "        if verbose:\n",
    "            print(\"done\")\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"building trie\")\n",
    "\n",
    "        name2index = MarisaAsDict(\n",
    "            marisa_trie.RecordTrie(\"i\", [(name, (k,)) for k, name in enumerate(ids)])\n",
    "        )\n",
    "        name2index.marisa.save(wikidata_ids_inverted_path)\n",
    "        if verbose:\n",
    "            print(\"done\")\n",
    "    return (ids, name2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import marisa_trie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, name2index = load_wikidata_ids(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article2id = marisa_trie.RecordTrie(\"i\").load(join(path, \"wikititle2wikidata.marisa\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article2id[\"europe\"][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from more_itertools import consecutive_groups\n",
    "\n",
    "\n",
    "def tokenize(sentence):\n",
    "    \"\"\"moses tokeniser\"\"\"\n",
    "    seq = \" \".join(word_tokenize(sentence))\n",
    "    seq = seq.replace(\" n't \", \"n 't \")\n",
    "    return seq.split()\n",
    "\n",
    "\n",
    "s = \"a bunch of text with a name like Francis Crick in it, and then Francis Crick in it again later\"\n",
    "tokens = tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.array(\n",
    "    [1 if token == \"Francis\" or token == \"Crick\" else 0 for token in tokens]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
