{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 20)\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from umap import UMAP\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# assemble the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/mnt/efs/wikipedia/good_article_links.pkl\", \"rb\") as fp:\n",
    "    graph_dict = pickle.load(fp)\n",
    "    G = nx.from_dict_of_lists(graph_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix = torch.Tensor(nx.adjacency_matrix(G).todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyDataset(Dataset):\n",
    "    def __init__(self, adjacency_matrix):\n",
    "        self.adjacency_matrix = adjacency_matrix\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.adjacency_matrix[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AdjacencyDataset(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size=50):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        # use the multiplicative midpoint between the two sizes\n",
    "        self.mid_size = int(\n",
    "            self.input_size // np.sqrt(self.input_size / self.embedding_size)\n",
    "        )\n",
    "        print()\n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Linear(in_features=self.input_size, out_features=self.mid_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features=self.mid_size, out_features=self.embedding_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(\n",
    "                in_features=self.embedding_size, out_features=self.embedding_size\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, embedding_size=50):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.embedding_size = embedding_size\n",
    "        # use the multiplicative midpoint between the two sizes\n",
    "        self.mid_size = int(\n",
    "            self.output_size // np.sqrt(self.output_size / self.embedding_size)\n",
    "        )\n",
    "\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                in_features=self.embedding_size, out_features=self.embedding_size\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features=self.embedding_size, out_features=self.mid_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(in_features=self.mid_size, out_features=self.output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decode(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size=50):\n",
    "        super().__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = input_size\n",
    "\n",
    "        self.encoder = Encoder(self.input_size, self.embedding_size)\n",
    "        self.decoder = Decoder(self.output_size, self.embedding_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedding = self.encoder(x)\n",
    "        decoded = self.decoder(embedding)\n",
    "        return nn.Sigmoid()(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(input_size=len(G.nodes), embedding_size=20).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "\n",
    "def train(model, train_loader, n_epochs, loss_function, optimiser, device=device):\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        loop = tqdm(train_loader)\n",
    "        for batch in loop:\n",
    "            data = batch.cuda(non_blocking=True)\n",
    "            target = batch.cuda(non_blocking=True)\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "            prediction = model(data)\n",
    "\n",
    "            loss = loss_function(prediction, target)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            loop.set_description(f\"Epoch {epoch + 1}/{n_epochs}\")\n",
    "            loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "trainable_parameters = filter(lambda p: p.requires_grad, autoencoder.parameters())\n",
    "\n",
    "loss_function = nn.BCELoss()\n",
    "optimiser = optim.Adam(trainable_parameters, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    model=autoencoder,\n",
    "    train_loader=dataloader,\n",
    "    loss_function=loss_function,\n",
    "    optimiser=optimiser,\n",
    "    n_epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_data = pd.Series(losses).rolling(window=15).mean()\n",
    "ax = loss_data.plot(subplots=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    embeddings_50d = (\n",
    "        autoencoder.encoder(adjacency_matrix.to(device)).detach().cpu().numpy()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_2d = UMAP(n_components=2, metric=\"cosine\").fit_transform(embeddings_50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(embeddings_2d)\n",
    "cluster = AgglomerativeClustering()\n",
    "df[\"cluster\"] = cluster.fit_predict(embeddings_50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x=0, y=1, c=df[\"cluster\"], cmap=\"Paired\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_names[df[df[\"cluster\"] == 1].index.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# query with nmslib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nmslib\n",
    "\n",
    "index = nmslib.init(method=\"hnsw\")\n",
    "index.addDataPointBatch(embeddings_50d)\n",
    "index.createIndex({\"post\": 2}, print_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_names = np.array(G.nodes)\n",
    "\n",
    "query_index = np.random.choice(len(node_names))\n",
    "query_embedding = embeddings_50d[query_index].reshape(1, -1)\n",
    "query_node_name = node_names[query_index]\n",
    "query_node_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, distances = index.knnQuery(query_embedding, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_names[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
