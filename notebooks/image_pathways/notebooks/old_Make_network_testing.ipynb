{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "from io import BytesIO\n",
    "import ast\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import boto3\n",
    "from scipy.spatial.distance import cdist\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from itertools import combinations\n",
    "import umap.umap_ as umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import the feature vectors from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://alexwlchan.net/2017/07/listing-s3-keys/\n",
    "def get_all_s3_keys(bucket):\n",
    "    \"\"\"Get a list of all keys in an S3 bucket.\"\"\"\n",
    "    keys = []\n",
    "\n",
    "    kwargs = {\"Bucket\": bucket}\n",
    "    while True:\n",
    "        resp = s3.list_objects_v2(**kwargs)\n",
    "        for obj in resp[\"Contents\"]:\n",
    "            keys.append(obj[\"Key\"])\n",
    "\n",
    "        try:\n",
    "            kwargs[\"ContinuationToken\"] = resp[\"NextContinuationToken\"]\n",
    "        except KeyError:\n",
    "            break\n",
    "\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"miro-images-feature-vectors\"\n",
    "s3 = boto3.client(\"s3\")\n",
    "keys = get_all_s3_keys(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"reduced_feature_vectors_20_dims\"\n",
    "keys = [k for k in keys if k.split(\"/\")[0] == folder_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors = {}\n",
    "for key in tqdm(keys):\n",
    "    obj = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "    read_obj = obj[\"Body\"].read()\n",
    "\n",
    "    feature_vectors[key] = np.frombuffer(read_obj, dtype=np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get the distances between feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors_list = list(feature_vectors.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[v for f in feature_vectors_list for v in f if \"nan\" in str(v)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat = cdist(feature_vectors_list, feature_vectors_list, metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat_top = np.zeros_like(dist_mat)\n",
    "dist_mat_top[:] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "\n",
    "# Find the top n neighbours for each image\n",
    "\n",
    "for i, _ in tqdm(enumerate(keys)):\n",
    "    arr = dist_mat[i].argsort()\n",
    "    top_args = arr[arr != i]\n",
    "    dist_mat_top[i][top_args[0:n]] = dist_mat[i][top_args[0:n]]\n",
    "    for j in top_args[0:n]:\n",
    "        dist_mat_top[j][i] = dist_mat[j][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Load images for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed_images_sample.pkl\", \"rb\") as handle:\n",
    "    images_original = pickle.load(handle)\n",
    "\n",
    "# Put in the same order as the feature vectors\n",
    "images = []\n",
    "for key in feature_vectors.keys():\n",
    "    image_key = os.path.basename(key)\n",
    "    images.append(images_original[image_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Plot the network of images connected to their closest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_rel_norm(value, min_val, max_val):\n",
    "    value = (value - min_val) / (max_val - min_val)\n",
    "    value = 1 / (value + 1e-8)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(dist_mat_top):\n",
    "\n",
    "    min_val = np.nanmin(dist_mat_top)\n",
    "    max_val = np.nanmax(dist_mat_top)\n",
    "\n",
    "    nodes = list(range(0, len(dist_mat_top[0])))\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(nodes)\n",
    "\n",
    "    # Put the weights in as the distances\n",
    "    # only inc nodes if they are in the closest related neighbours\n",
    "    for start, end in list(combinations(nodes, 2)):\n",
    "        if ~np.isnan(dist_mat_top[start, end]):\n",
    "            # Since in the plot a higher weight makes the nodes closer,\n",
    "            # but a higher value in the distance matrix means the images are further away,\n",
    "            # we need to inverse the weight (so higher = closer)\n",
    "            G.add_edge(\n",
    "                start,\n",
    "                end,\n",
    "                weight=inv_rel_norm(dist_mat_top[start, end], min_val, max_val),\n",
    "            )\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(G, image_names=None):\n",
    "\n",
    "    pos = nx.spring_layout(G)\n",
    "\n",
    "    plt.figure(3, figsize=(10, 10))\n",
    "    nx.draw(G, pos, node_size=10)\n",
    "    for p in pos:  # raise text positions\n",
    "        pos[p][1] += 0.06\n",
    "    if image_names:\n",
    "        image_names_dict = {k: str(k) + \" \" + v for k, v in enumerate(image_names)}\n",
    "        nx.draw_networkx_labels(G, pos, labels=image_names_dict)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = create_graph(dist_mat_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Visualise the clusters by reducing dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()\n",
    "embedding_fv = reducer.fit_transform(feature_vectors_list)\n",
    "embedding_fv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/gaborvecsei/plants-t-sne\n",
    "def visualize_scatter_with_images(X_2d_data, images, figsize=(45, 45), image_zoom=1):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    artists = []\n",
    "    for xy, i in zip(X_2d_data, images):\n",
    "        x0, y0 = xy\n",
    "        img = OffsetImage(i, zoom=image_zoom)\n",
    "        ab = AnnotationBbox(img, (x0, y0), xycoords=\"data\", frameon=False)\n",
    "        artists.append(ax.add_artist(ab))\n",
    "    ax.update_datalim(X_2d_data)\n",
    "    ax.autoscale()\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[a, b] for (a, b) in zip(embedding_fv[:, 0], embedding_fv[:, 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_with_images(x_data, images=images, image_zoom=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5a. Pick 2 images and look at the route between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names_dict = {k: v for k, v in enumerate(images)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = np.random.choice(list(image_names_dict))\n",
    "node2 = np.random.choice(list(image_names_dict))\n",
    "\n",
    "node_path = nx.dijkstra_path(G, node1, node2, weight=None)\n",
    "print(node_path)\n",
    "\n",
    "show_images = [images[i] for i in node_path]\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "columns = len(show_images)\n",
    "for i, image in enumerate(show_images):\n",
    "    ax = plt.subplot(len(show_images) / columns + 1, columns, i + 1)\n",
    "    ax.set_axis_off()\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b. User sets number of images in pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5c. Pick 3 images and look at the paths between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = np.random.choice(list(image_names_dict))\n",
    "node2 = np.random.choice(list(image_names_dict))\n",
    "node3 = np.random.choice(list(image_names_dict))\n",
    "\n",
    "node_path_a = nx.dijkstra_path(G, node1, node2, weight=None)\n",
    "node_path_b = nx.dijkstra_path(G, node2, node3, weight=None)\n",
    "node_path_c = nx.dijkstra_path(G, node3, node1, weight=None)\n",
    "node_path_3 = node_path_a[:-1] + node_path_b[:-1] + node_path_c\n",
    "print(node_path_3)\n",
    "\n",
    "show_images = [images[i] for i in node_path_3]\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "columns = len(show_images)\n",
    "for i, image in enumerate(show_images):\n",
    "    ax = plt.subplot(len(show_images) / columns + 1, columns, i + 1)\n",
    "\n",
    "    if node_path_3[i] in [node1, node2, node3]:\n",
    "        ax.set(title=\"NODE\")\n",
    "    ax.set_axis_off()\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Plot route on graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/gaborvecsei/plants-t-sne\n",
    "def visualize_scatter_pathway_with_images(\n",
    "    X_2d_data, pathway, images, figsize=(45, 45), image_zoom=1\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    x_path = [x_data[c][0] for c in node_path]\n",
    "    y_path = [x_data[c][1] for c in node_path]\n",
    "\n",
    "    artists = []\n",
    "    for num, (xy, i) in enumerate(zip(X_2d_data, images)):\n",
    "        x0, y0 = xy\n",
    "        if num in pathway:\n",
    "            img = OffsetImage(i, zoom=image_zoom * 2, alpha=0.8)\n",
    "        else:\n",
    "            img = OffsetImage(i, zoom=image_zoom, alpha=0.2)\n",
    "        ab = AnnotationBbox(img, (x0, y0), xycoords=\"data\", frameon=False)\n",
    "        artists.append(ax.add_artist(ab))\n",
    "    ax.update_datalim(X_2d_data)\n",
    "    ax.autoscale()\n",
    "    plt.plot(x_path, y_path, \"ro-\", linewidth=5)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_scatter_pathway_with_images(\n",
    "    x_data, node_path, images=images, figsize=(30, 30), image_zoom=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
