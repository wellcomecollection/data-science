{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "041e468a-064a-43fa-963f-75242cc9c9ce",
   "metadata": {},
   "source": [
    "# Downloading subject headings from the library of congress \n",
    "LoC don't make it easy to get a complete list of subject headings. The neatest route seems to be the [downloads section of the LoC website](https://id.loc.gov/download/), where they make a [skos](https://www.w3.org/2004/02/skos/), [ndjson](http://ndjson.org/) version of the headings available.\n",
    "\n",
    "In this notebook we'll download the file, and parse out the useful information from it. In the next notebook we'll focus on getting meaningful results from the intersection of this dataset and the queries sent through [wellcomecollection.org/collections](https://wellcomecollection.org/collections)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614c50b9-0487-4d30-84b9-3100d4be8673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "import httpx\n",
    "import orjson\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49fc8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://lds-downloads.s3.amazonaws.com/lcsh.skos.ndjson.zip\"\n",
    "filename = Path(url).name\n",
    "data_dir = Path(\"../data/lcsh\")\n",
    "\n",
    "if not data_dir.exists():\n",
    "    data_dir.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f957157a-e0e0-48b7-9398-2f02774317ed",
   "metadata": {},
   "source": [
    "We've defined where we want to fetch the file from, and where we want to save it - now we just need to download it. It's a fairly large file so I've added a progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55a0e9a-74d6-4563-91a0-3e14c1ae40a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = data_dir / \"lcsh\" / filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c132cc1-78e1-4438-9d89-01045cdfd37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not file_path.exists():\n",
    "    with open(file_path, \"wb\") as download_file:\n",
    "        with httpx.stream(\"GET\", url) as response:\n",
    "            total = int(response.headers[\"Content-Length\"])\n",
    "            with tqdm(\n",
    "                total=total, unit_scale=True, unit_divisor=1024, unit=\"B\", desc=filename\n",
    "            ) as progress:\n",
    "                num_bytes_downloaded = response.num_bytes_downloaded\n",
    "                for chunk in response.iter_bytes():\n",
    "                    download_file.write(chunk)\n",
    "                    progress.update(\n",
    "                        response.num_bytes_downloaded - num_bytes_downloaded\n",
    "                    )\n",
    "                    num_bytes_downloaded = response.num_bytes_downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa786979-4749-4a4c-8073-76803ed492a9",
   "metadata": {},
   "source": [
    "We also need to unzip the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416c5270",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a9205a-94a6-4305-a399-4fda4a23124d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## extract the useful data\n",
    "This is a pretty big file - let's find out how many lines (ie records) it contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cdd4de-26dd-453c-b9dd-47f4a3707ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! wc -l ../data/lcsh/lcsh.skos.ndjson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86390620-4474-4e28-97e9-045b368568fd",
   "metadata": {},
   "source": [
    "450645 lines is probably big enough to be worth iterating through it gradually, rather than reading it all at once. Let's set up a function to yield lines one-by-one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8826c0-79c1-4524-893e-fea47ac13ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_records(file_path):\n",
    "    with open(file_path) as f:\n",
    "        while line := f.readline():\n",
    "            yield orjson.loads(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0ebf79-67b6-47b8-851d-e9fcec50bffe",
   "metadata": {},
   "source": [
    "all that's left to do now is work through each of those records and extract the LCSH ID and the heading (`prefLabel`) for each record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3422a3-aff2-4ddd-94b9-b7b2da3c090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "generator = load_records(data_dir / Path(url).stem)\n",
    "\n",
    "for record in tqdm(generator, total=450645):\n",
    "    lcsh_id = Path(record[\"@context\"][\"about\"]).name\n",
    "    for item in record[\"@graph\"]:\n",
    "        if item[\"@id\"] == record[\"@context\"][\"about\"]:\n",
    "            try:\n",
    "                data[lcsh_id] = item[\"skos:prefLabel\"][\"@value\"]\n",
    "            except KeyError:\n",
    "                # have inspected these lines. it looks like they're\n",
    "                # all duplicate/deleted records\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5c60e8-8aa0-4b98-8d61-a5e2f209aabd",
   "metadata": {},
   "source": [
    "Now we can save our cleaned records to the `/data` directory for use in future notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7233eef4-93bc-4234-baf9-52d428d05103",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir / \"lcsh_ids_and_labels.json\", \"wb\") as f:\n",
    "    f.write(orjson.dumps(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
