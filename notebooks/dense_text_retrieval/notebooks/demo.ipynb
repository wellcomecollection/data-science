{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a62e9c2-da30-4069-ac69-6d95d88f0965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import httpx\n",
    "import spacy\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647cce4b-1e8e-44c4-8101-16137216fe32",
   "metadata": {},
   "source": [
    "# download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fa2bce-e97b-4a8f-81e7-300e56e97f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0500a010-5be0-4bd0-a9e1-1d1cab2d6190",
   "metadata": {},
   "source": [
    "# demo embedding and similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59ad128-1bd0-4517-a247-5595f762ce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d37eb42-9c62-4d32-a665-2270976616bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "apple1 = nlp(\"Apple shares rose on the news.\")\n",
    "apple2 = nlp(\"Apple sold fewer iPhones this quarter.\")\n",
    "apple3 = nlp(\"Apple pie is delicious.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5543ac-cca7-4b9b-8b87-6f5cc66e5c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(apple1.similarity(apple2))\n",
    "print(apple1.similarity(apple3))\n",
    "print(apple2.similarity(apple3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892b1799-123b-48d7-b06a-5474ea37b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "apple1.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea7e21b-e1d2-4862-abce-3ebf34aef248",
   "metadata": {},
   "source": [
    "- encode all the titles\n",
    "- produce vectors for all of them\n",
    "- train an lsh model\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0383b7-310c-4789-a8b8-0990e4c15d07",
   "metadata": {},
   "source": [
    "# download catalogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa02b688-7b07-46ca-873f-3771b9be74a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data\")\n",
    "\n",
    "if not data_dir.exists():\n",
    "    data_dir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f817f1-1908-43c5-8cfe-a7f1a25e7437",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://data.wellcomecollection.org/catalogue/v2/works.json.gz\"\n",
    "filename = Path(url).name\n",
    "zipped_works_file_path = data_dir / filename\n",
    "works_file_path = data_dir / zipped_works_file_path.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b99d9a-3bfe-43cb-9136-7cefb0903278",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not works_file_path.exists():\n",
    "    if not zipped_works_file_path.exists():\n",
    "        with open(zipped_works_file_path, \"wb\") as download_file:\n",
    "            with httpx.stream(\"GET\", url, timeout=999999) as response:\n",
    "                total = int(response.headers[\"Content-Length\"])\n",
    "                with tqdm(\n",
    "                    total=total,\n",
    "                    unit_scale=True,\n",
    "                    unit_divisor=1024,\n",
    "                    unit=\"B\",\n",
    "                    desc=filename,\n",
    "                ) as progress:\n",
    "                    num_bytes_downloaded = response.num_bytes_downloaded\n",
    "                    for chunk in response.iter_bytes():\n",
    "                        download_file.write(chunk)\n",
    "                        progress.update(\n",
    "                            response.num_bytes_downloaded - num_bytes_downloaded\n",
    "                        )\n",
    "                        num_bytes_downloaded = response.num_bytes_downloaded\n",
    "\n",
    "    with gzip.open(zipped_works_file_path, \"rb\") as f_in:\n",
    "        with open(works_file_path, \"wb\") as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad1abfd-fd06-4c57-8b2f-9d513adae6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_records(path):\n",
    "    with open(path) as f:\n",
    "        while line := f.readline():\n",
    "            yield json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce509a79-dd0e-4b5b-b89a-97dbd096600c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8abc83-ad32-4286-bc9d-ebc00ecd8b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = load_records(works_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7612c3c-848a-4d9d-8e9d-c6cbe8947372",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = next(iter(generator))\n",
    "nlp(record[\"title\"]).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2fd24a-9e51-43d2-a286-b91d7b188ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f9ce4-b48b-41a1-8761-81b0e82353e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = {}\n",
    "for record in tqdm(load_records(works_file_path), total=1151916):\n",
    "    docs[record[\"id\"]] = {\n",
    "        \"title\": record[\"title\"],\n",
    "        \"embedding\": nlp(record[\"title\"]).vector,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70c2d77-c57b-4e0e-9cd7-4ea899dbbfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.stack([doc[\"embedding\"] for doc in docs.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968e9d82-965b-4cb1-8c2a-f14b44f16522",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6879dca-95b5-40e3-80ea-a3abe69a5f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56470f9a-2d5c-4576-82b3-010c2ced2edf",
   "metadata": {},
   "source": [
    "# lsh model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4c0c93-0528-4153-bd36-67654f405f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "class LSHEncoder:\n",
    "    def __init__(self, model_path=None):\n",
    "        if model_path:\n",
    "            with open(model_path, \"rb\") as f:\n",
    "                self.models = pickle.load(f)\n",
    "        else:\n",
    "            self.models = []\n",
    "\n",
    "    @staticmethod\n",
    "    def encode_for_elasticsearch(clusters):\n",
    "        return [f\"{i}-{val}\" for i, val in enumerate(clusters)]\n",
    "\n",
    "    def __call__(self, feature_vectors):\n",
    "        feature_groups = np.split(feature_vectors, len(self.models), axis=1)\n",
    "\n",
    "        clusters = np.stack(\n",
    "            [\n",
    "                model.predict(feature_group)\n",
    "                for model, feature_group in zip(self.models, feature_groups)\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        return [LSHEncoder.encode_for_elasticsearch(c) for c in clusters]\n",
    "\n",
    "    def train(self, feature_vectors, m, n):\n",
    "        feature_groups = np.split(feature_vectors, indices_or_sections=n, axis=1)\n",
    "        model_list = []\n",
    "        for feature_group in tqdm(feature_groups):\n",
    "            clustering_alg = KMeans(n_clusters=m, n_jobs=-1).fit(feature_group)\n",
    "            model_list.append(clustering_alg)\n",
    "        self.models = model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddb2ada-adbf-4dab-b817-533ad20b8791",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh = LSHEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fdd7f1-0f2f-43e0-9d5f-805de9badf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh.train(embeddings, 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b81e2c-b7f3-408a-919b-80ff611cde56",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh(embeddings[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e72cff5-427b-4aea-825b-6b8800459b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
